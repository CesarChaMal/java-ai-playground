server.port=${PORT:8080}
logging.level.org.atmosphere = warn
spring.mustache.check-template-location = false

# Launch the default browser when starting the application in development mode
vaadin.launch-browser=true

# Workaround for https://github.com/vaadin/hilla/issues/842
spring.devtools.restart.additional-exclude=dev/hilla/openapi.json
# To improve the performance during development.
# For more information https://vaadin.com/docs/flow/spring/tutorial-spring-configuration.html#special-configuration-parameters
vaadin.allowed-packages=com.vaadin,org.vaadin,dev.hilla,com.example.application
spring.jpa.defer-datasource-initialization = true

# LangChain4j properties
langchain4j.open-ai.streaming-chat-model.api-key=${OPENAI_API_KEY}
langchain4j.open-ai.streaming-chat-model.model-name=gpt-4-turbo
langchain4j.open-ai.streaming-chat-model.temperature=0
langchain4j.open-ai.embedding-model.api-key=${OPENAI_API_KEY}
langchain4j.open-ai.streaming-chat-model.strict-tools=true

#langchain4j.base-url=http://localhost:11434
#langchain4j.ollama.chat-model.model-name=mistral
#langchain4j.ollama.chat-model.temperature=0.0
#langchain4j.ollama.embedding-model.model-name=mistral

# Logging properties
langchain4j.open-ai.streaming-chat-model.log-requests=true
logging.level.dev.langchain4j=DEBUG
logging.level.dev.ai4j.openai4j=DEBUG
logging.level.ai.djl=OFF

vaadin.productionMode=false
